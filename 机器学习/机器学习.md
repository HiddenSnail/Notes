
# 机器学习笔记

## 1. 梯度下降概念

导数的通俗理解：**表示一个函数的变化率**

例如：当f(x)=x^2时，它的导函数为f'(x)=2x；当x=1时。f(1)=1表示f(x)函数的结果为1, 而f'(x)=2表示，函数f(x)在x=1处的斜率为2，也就是说变化率为2。

可以发现，当我们知道了函数f(x)的导函数f'(x)时，我们可以通过f'(x)近似逼近出f(x)的实际图像

```
f'(x) = ( f(x') - f(x) ) / (x' - x), 其中 { x' > x , x' - x -> 0 }

记 x' - x = Δx
=> Δx * f'(x) = f(x') - f(x)
=> f(x') = f(x) + Δx * f'(x)

很明显，在已知导函数的情况下，只要Δx足够小，那么f(x')就是准确的

当x = 1, Δx = -0.1时，如何找到最低点呢? 在课堂上我们学过，导数为0的点就是极值点。

而计算机的迭代步骤如下：
f'(1) = 2, 则x = x - 0.1 * 2 = 0.8
f'(0.8) = 1.6, 则 x = x - 0.1 * 1.6 = 0.62
f'(0.62) = 1.24, 则 x = x - 0.1 * 1.24 = 0.496
...

凸函数存在全局最优解：
依据梯度下降法的收敛性(待研究)，类似迭代N次后, 则f'(x)就会无限趋近于0, 则这时候便可以取到极小值

```